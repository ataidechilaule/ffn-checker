#!/usr/bin/env python3
import argparse
import json
import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import torch
from transformers import AutoModel, AutoTokenizer, AutoConfig
from datasets import load_dataset
from tqdm import tqdm
import numpy as np

from fault_injection import FaultInjector


def attach_ffn_hooks(model, injector, location_name, error_type, layer_idx=-1):
    """
    Regista hooks na FFN de uma camada específica do BERT.
    location_name: 'first_gemm', 'after_activation', 'second_gemm', 'final_output'
    """
    # BERT-like: encoder.layer[i].intermediate.dense (W1), encoder.layer[i].output.dense (W2)
    encoder_layer = model.encoder.layer[layer_idx]
    intermediate_dense = encoder_layer.intermediate.dense   # W1
    output_dense = encoder_layer.output.dense               # W2
    activation_fn = encoder_layer.intermediate.intermediate_act_fn

    hooks = []

    def hook_first_gemm(module, input, output):
        # output: [batch, seq, d_ff]
        batch_idx = 0
        seq_idx = np.random.randint(0, output.shape[1])
        dim_idx = np.random.randint(0, output.shape[2])
        injector.inject(output, (batch_idx, seq_idx, dim_idx), error_type)

    def hook_after_activation(module, input, output):
        # output: [batch, seq, d_ff]
        batch_idx = 0
        seq_idx = np.random.randint(0, output.shape[1])
        dim_idx = np.random.randint(0, output.shape[2])
        injector.inject(output, (batch_idx, seq_idx, dim_idx), error_type)

    def hook_second_gemm(module, input, output):
        # output: [batch, seq, d_model]
        batch_idx = 0
        seq_idx = np.random.randint(0, output.shape[1])
        dim_idx = np.random.randint(0, output.shape[2])
        injector.inject(output, (batch_idx, seq_idx, dim_idx), error_type)

    def hook_final_output(module, input, output):
        # mesma coisa que second_gemm, mas conceitualmente "final_output"
        batch_idx = 0
        seq_idx = np.random.randint(0, output.shape[1])
        dim_idx = np.random.randint(0, output.shape[2])
        injector.inject(output, (batch_idx, seq_idx, dim_idx), error_type)

    if location_name == "first_gemm":
        hooks.append(intermediate_dense.register_forward_hook(hook_first_gemm))
    elif location_name == "after_activation":
        # activation_fn não é um módulo separado em BERT, então usamos um hook na saída de W1
        # e aplicamos a ativação manualmente seria mais complexo; aqui assumimos que
        # intermediate_act_fn é um módulo (em alguns modelos é). Se não for, podemos
        # usar um hook no encoder_layer.intermediate.
        hooks.append(encoder_layer.intermediate.register_forward_hook(hook_after_activation))
    elif location_name == "second_gemm":
        hooks.append(output_dense.register_forward_hook(hook_second_gemm))
    elif location_name == "final_output":
        hooks.append(output_dense.register_forward_hook(hook_final_output))
    else:
        raise ValueError(f"Unknown location: {location_name}")

    return hooks


def run_vulnerability_analysis(
    model_name: str,
    error_types: list,
    num_faults: int,
    output_path: str
):
    print(f"=== Vulnerability Analysis for {model_name} ===\n")

    print("Loading model...")
    config = AutoConfig.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    model.eval()
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    print(f"Model loaded: {config.hidden_size} hidden dim\n")

    print("Loading dataset...")
    dataset = load_dataset("glue", "mrpc", split="train[:100]")

    injector = FaultInjector(error_types=error_types)

    results = {
        'model': model_name,
        'num_faults': num_faults,
        'error_types': error_types,
        'locations': {}
    }

    locations = [
        'first_gemm',
        'after_activation',
        'second_gemm',
        'final_output'
    ]

    for location in locations:
        print(f"\nTesting location: {location}")
        results['locations'][location] = {}

        for error_type in error_types:
            print(f"  Error type: {error_type}")

            failures = 0
            total = 0

            pbar = tqdm(total=num_faults, desc=f"    {error_type}", leave=False)

            for fault_idx in range(num_faults):
                sample = dataset[fault_idx % len(dataset)]
                inputs = tokenizer(
                    sample['sentence1'],
                    sample['sentence2'],
                    return_tensors='pt',
                    padding='max_length',
                    max_length=128,
                    truncation=True
                )

                # Regista hooks para este fault específico
                hooks = attach_ffn_hooks(model, injector, location, error_type)

                with torch.no_grad():
                    try:
                        outputs = model(**inputs)
                        # Simples "loss proxy": média da última camada de saída
                        hidden = outputs.last_hidden_state
                        loss = hidden.mean()

                        if torch.isnan(loss) or torch.isinf(loss):
                            failures += 1
                        total += 1

                    except Exception:
                        failures += 1
                        total += 1

                # Remove hooks para não acumular
                for h in hooks:
                    h.remove()

                pbar.update(1)

            pbar.close()

            failure_rate = failures / total if total > 0 else 0.0
            results['locations'][location][error_type] = failure_rate

            print(f"    Failure rate: {failure_rate*100:.1f}%")

    print(f"\nSaving results to {output_path}")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=2)

    print("\n=== Summary ===")
    for location in locations:
        print(f"\n{location}:")
        for error_type in error_types:
            rate = results['locations'][location][error_type]
            print(f"  {error_type}: {rate*100:.1f}%")

    print("\nDone!")
    return results


def main():
    parser = argparse.ArgumentParser(
        description="Run vulnerability analysis on LLM FFN operations"
    )
    parser.add_argument(
        '--model',
        type=str,
        default='bert-base-uncased',
        help='HuggingFace model name'
    )
    parser.add_argument(
        '--error_types',
        nargs='+',
        default=['INF', 'NaN', 'near-INF'],
        help='Error types to inject'
    )
    parser.add_argument(
        '--num_faults',
        type=int,
        default=1000,
        help='Number of faults per location/type'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='results/vulnerability.json',
        help='Output JSON file path'
    )

    args = parser.parse_args()

    run_vulnerability_analysis(
        model_name=args.model,
        error_types=args.error_types,
        num_faults=args.num_faults,
        output_path=args.output
    )


if __name__ == "__main__":
    main()
